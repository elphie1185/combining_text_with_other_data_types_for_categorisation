{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from datasets import Dataset\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    LabelEncoder,\n",
    ")\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# -------------------------------------\n",
    "# Display\n",
    "# -------------------------------------\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and split into a training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(\"data/wine_data.csv\")\n",
    "bins = [0, 87, 94, np.inf]\n",
    "names = [\"neutral\", \"good\", \"excellent\"]\n",
    "\n",
    "wine_df[\"rating\"] = pd.cut(wine_df[\"points\"], bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURE = \"price\"\n",
    "CATEGORICAL_FEATURE = \"variety\"\n",
    "TEXT_FEATURE = \"description\"\n",
    "TARGET = \"rating\"\n",
    "FEATURES = [TEXT_FEATURE, NUMERICAL_FEATURE, CATEGORICAL_FEATURE]\n",
    "\n",
    "wine_df = wine_df[FEATURES + [TARGET]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(wine_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- preprocess numerical and categorical variables \n",
    "- tokenize text data\n",
    "- extract vector representation of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_number():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        StandardScaler(),\n",
    "    )\n",
    "\n",
    "def preprocess_categories():\n",
    "    return make_pipeline(\n",
    "       SimpleImputer(strategy=\"constant\", fill_value=\"other\", missing_values=np.nan),\n",
    "       OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "    )\n",
    "\n",
    "def create_preprocessor():\n",
    "\n",
    "    transformers = [\n",
    "        (\"num_preprocessor\", preprocess_number(), [NUMERICAL_FEATURE]),\n",
    "        (\"cat_preprocessor\", preprocess_categories(), [CATEGORICAL_FEATURE]),\n",
    "    ]\n",
    "\n",
    "    return ColumnTransformer(transformers=transformers, remainder=\"drop\")\n",
    "\n",
    "\n",
    "column_transformer = create_preprocessor()\n",
    "column_transformer.set_output(transform=\"pandas\")\n",
    "preprocessed_num_cat_features_df = column_transformer.fit_transform(\n",
    "    train_df[[NUMERICAL_FEATURE, CATEGORICAL_FEATURE]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "def tokenized_pytorch_tensors(\n",
    "        df: pd.DataFrame,\n",
    "        column_list: list\n",
    "    ) -> Dataset:\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    transformers_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    def tokenize(model_inputs_batch: Dataset) -> Dataset:\n",
    "        return tokenizer(\n",
    "            model_inputs_batch[TEXT_FEATURE],\n",
    "            padding=True,\n",
    "            max_length=120,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = transformers_dataset.map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        batch_size=128\n",
    "    )\n",
    "\n",
    "    tokenized_dataset.set_format(\n",
    "        \"torch\",\n",
    "        columns=column_list\n",
    "    )\n",
    "\n",
    "    columns_to_remove = set(tokenized_dataset.column_names) - set(column_list)\n",
    "\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns(list(columns_to_remove))\n",
    "\n",
    "    return tokenized_dataset\n",
    "\n",
    "print(\"Tokenize text in Dataset of Pytorch tensors\")\n",
    "train_df[TEXT_FEATURE] = train_df[TEXT_FEATURE].fillna(\"\")\n",
    "tokenized_df = tokenized_pytorch_tensors(\n",
    "    train_df[[TEXT_FEATURE]],\n",
    "    column_list=[\"input_ids\", \"attention_mask\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_state_from_text_inputs(df) -> pd.DataFrame:\n",
    "\n",
    "    def extract_hidden_states(batch):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "        # keys are input_ids and attention_mask\n",
    "        # values are both tensor[batch_size, max_number_of_tokens_in_batch]\n",
    "        inputs = {\n",
    "            k: v.to(device)\n",
    "            for k, v in batch.items()\n",
    "            # this avoids us trying to pass in other features in the dataset\n",
    "            if k in tokenizer.model_input_names\n",
    "        }\n",
    "\n",
    "        # turn off gradient calculation as we don't need it\n",
    "        with torch.no_grad():\n",
    "            # final output of the model, the representation of the text tokens\n",
    "            # use ** as the model takes input_ids and attention_mask arguments\n",
    "            last_hidden_state = model(**inputs).last_hidden_state\n",
    "            # get the CLS token, which is the first one\n",
    "            # [:, 0] gives us a row for each batch with the first column of 768 for each\n",
    "            return {\"cls_hidden_state\": last_hidden_state[:, 0].cpu().numpy()}\n",
    "\n",
    "    cls_dataset = df.map(extract_hidden_states, batched=True, batch_size=128)\n",
    "    cls_dataset.set_format(type=\"pandas\")\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        cls_dataset[\"cls_hidden_state\"].to_list(),\n",
    "        columns=[f\"feature_{n}\" for n in range(1, 769)],\n",
    "    )\n",
    "\n",
    "print(\"Extract text feature hidden state\")\n",
    "hidden_states_df = hidden_state_from_text_inputs(tokenized_df)\n",
    "print(f\"Data with hidden state shape: {hidden_states_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving preprocessed features and targets\")\n",
    "preprocessed_data = pd.concat(\n",
    "    [\n",
    "        preprocessed_num_cat_features_df,\n",
    "        hidden_states_df,\n",
    "        train_df[TARGET]\n",
    "    ],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the lightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  encode target and rename features\n",
    "TARGET_CATEGORIES = [\"negative\", \"positive\", \"neutral\"]\n",
    "le = LabelEncoder().fit(TARGET_CATEGORIES)\n",
    "preprocessed_data[\"encoded_target\"] = le.transform(preprocessed_data[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "features = [col for col in list(preprocessed_data.columns) if col not in [TARGET, \"encoded_target\"]]\n",
    "\n",
    "# create the model\n",
    "lgbm_clf = lgbm.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    num_leaves=10,\n",
    "    objective=\"multiclass\",\n",
    ")\n",
    "\n",
    "lgbm_clf.fit(preprocessed_data[features], preprocessed_data[\"encoded_target\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_num_cat_features_test_df = column_transformer.transform(\n",
    "        test_df[[NUMERICAL_FEATURE, CATEGORICAL_FEATURE]]\n",
    ")\n",
    "\n",
    "# preprocess the text column\n",
    "test_df[TEXT_FEATURE] = test_df[TEXT_FEATURE].fillna(\"\")\n",
    "tokenized_test_text_df = tokenized_pytorch_tensors(\n",
    "    test_df[[TEXT_FEATURE]],\n",
    "    column_list=[\"input_ids\", \"attention_mask\"]\n",
    ")\n",
    "\n",
    "#  extract last hidden state\n",
    "hidden_states_test_df = hidden_state_from_text_inputs(tokenized_test_text_df)\n",
    "\n",
    "preprocessed_eval_df = pd.concat(\n",
    "    [\n",
    "        preprocessed_num_cat_features_test_df,\n",
    "        hidden_states_test_df,\n",
    "        test_df[TARGET]\n",
    "    ],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "preprocessed_eval_df = preprocessed_eval_df.rename(\n",
    "        columns = lambda x:re.sub(\"[^A-Za-z0-9_]+\", \"\", x)\n",
    ")\n",
    "\n",
    "actual = preprocessed_eval_df[TARGET].values\n",
    "predictions = lgbm_clf.predict(preprocessed_eval_df[features])\n",
    "decoded_predictions = le.inverse_transform(predictions)\n",
    "\n",
    "accuracy_score(actual, decoded_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
